---
title: "Integrating CPC Data"
---



# libraries that we'll need 

```{r}
library(data.table)
library(lubridate)
library(tidyr)
library(dplyr)
library(openair)
library(baseline)
```

# importing data (not including CPC)

1. Import Aethalometer data 

UV BC1, Blue BC1, Green BC1, Red BC1, and IR BC1

```{r}
aeth_data <- fread("data/cpc/Data from Week 1/AETHLOMETER/MA350-0093_S0024_200923112201.CSV")

# removing unnecessary variables 

aeth_data <- aeth_data[ , c( "Date / time local",  "Timezone offset (mins)" , "Date local (yyyy/MM/dd)", "Time local (hh:mm:ss)", "Status" ,  "UV BC1", "Blue BC1", "Green BC1", "Red BC1", "IR BC1")]

# formatting date time 

aeth_data$date <- ymd_hms(aeth_data$`Date / time local`, tz= "America/New_York")


```


# Concatenate CPC data 

2.	Concatenate the CPC data. Each day is a new file, so you'll need to combine them all into a single vector.

```{r}
nm <- list.files(path="data/cpc/Data from Week 1/MCPC data/", all.files = TRUE, full.names = TRUE, pattern="*.TXT")

cpc_upload <- do.call(rbind, lapply(nm, function(x) read.delim(file=x, header = TRUE, skip = 13) ) )

# removing unncessary variables 

cpc_upload <- cpc_upload[ , c("X.YY.MM.DD", "HR.MN.SC", "concent", "fillcnt"  )]

#formatting datetime

cpc_upload$date <- with(cpc_upload, ymd(`X.YY.MM.DD`) + hms(`HR.MN.SC`), tz = "America/New_York") 

```


For the CPC, the vector your care about is "concent." The other one to pay attention to is "fillcnt," which is an error warning that is nonzero if the working fluid ran dry

## Removing fillcnt data 

```{r} 
cpc_upload <- na.omit(cpc_upload) 

length(which(cpc_upload$fillcnt != 0))

indxs <- which(cpc_upload$fillcnt != 0)
```

```{r}
list_indxs = vector()
min5 = 1*60*5;

for(indx in (2:length(indxs))){
  if(indxs[indx] -1 != indxs[indx-1] &&  !(indxs[indx-1] %in% list_indxs)){
    list_indxs <- append(list_indxs, indxs[indx-1])
    list_indxs <- append(list_indxs, indxs[indx])
    if(indxs[indx-1] == 343){
      
    }
    else{
    # remove 5 minutes past the indx where indx -1 stops 
      
    # remove 5 minutes before 
    }

  }  
}
```


```{r}

```


# Check for anything funky 

1.2. identify anything funky like negative values. You know the drill.

Gutcheck: 
-# of negative values 
-timeplots (for obvious trends)
- summary stats 

```{r}
timePlot(aeth_data, pollutant = c("UV BC1", "Blue BC1", "Green BC1", "Red BC1", "IR BC1"))
```

-Showing spikes at the same time 
-Has baseline with isolated peak events 
-Looks indicative of individual plume events! 
-I see some negative values on Sept 29

```{r}
timePlot(cpc_upload, pollutant = "concent")
```
- No negative values 
- Quiet period on Sept 29 
- High spike on Sept 23? 

```{r}
aeth_data<- na.omit(aeth_data)
for(pollutant in list(aeth_data$`UV BC1`, aeth_data$`Blue BC1`, aeth_data$`Green BC1`, aeth_data$`Red BC1`, aeth_data$`IR BC1`)){
  print(sum(pollutant < 0))
}
```
So there are a number of negative values. It's about an hour to two hours of negative data for each variable 

```{r}
cpc_upload <- na.omit(cpc_upload)
sum(cpc_upload$concent < 0)
```
No negative values for this.


# importing sn45 and sn46 

3.	Download data from SN 045 and 046 from the same time period (23-28 Sep).

```{r}
sn45_cpc <- fread("data/cpc/Data from Week 1/sn45cpc.csv", header = TRUE)
sn45_cpc$date <- ymd_hms(sn45_cpc$timestamp_local, tz = "America/New_York")
sn46_cpc <- fread("data/cpc/Data from Week 1/sn45cpc.csv", header = TRUE)
sn46_cpc$date <- ymd_hms(sn46_cpc$timestamp_local, tz = "America/New_York")
```
Correcting no and no2 

```{r}
no_ae_filter <- function(sensor){
  # NO AE Filter 

#create a vector that shows the derivatives 
no_ae_derivative <- c(0,diff(sensor$no_ae, na.rm = TRUE))
#creating logical vector to pick which things to get rid of 
logical_vec <- abs(no_ae_derivative) < abs(2.5*(sd(no_ae_derivative, na.rm=TRUE)))

#make sure SN NO values that == 0 are not removed
if (any(sensor$no == 0, na.rm = TRUE)){
  sensor$no <- replace(sensor$no, 0, 0.00001)
}
# if logical_vec is true, then set the NO value to NA 
sensor$no <- sensor$no * logical_vec
sensor$no <- replace(sensor$no, 0, NA)

return(sensor)
}
```

```{r}
no_baseline_filter <- function(sensor){
  # NO BASELINE CORRECTION 

tz(sensor$date) <- "America/New_York"
# create day column
sensor[, day := as.Date(date, format="%Y-%m-%d", tz = "America/New_York")]
# create corrected column 
sensor[, correctedNO := seq(0,0,length.out= length(sensor$no))]
sensor$correctedNO[sensor$correctedNO == 0] <- NA  #set them actually to NA

dropNAsensor<- sensor[!is.na(sensor$no), ] # drop NO NAs

unique_days <- c(unique(dropNAsensor$day, na.rm=TRUE)) #get all of the unique days in the sensor

for (i in 2:(length(unique_days)-1)){ #for all days
  temp <- subset(dropNAsensor, day %in% unique_days[i], c("day", "no", "date")) #create temp dataset

  if (nrow(temp) > 550){
    wholebase.peakDetection <- baseline(t(temp$no), method='peakDetection',left=50, right=50, lwin=10, rwin=10) #baseline correction
  
  #replace the correctedNO column values with the baseline correction from earlier
  dropNAsensor$correctedNO[which(dropNAsensor$date == temp$date[1]): which(dropNAsensor$date == tail(temp$date, n=1))] <-    c(getCorrected(wholebase.peakDetection))
  }
  
  else{
    if (sum(temp$no < 0, na.rm = TRUE) / nrow(temp) < 0.25){
      dropNAsensor$correctedNO[which(dropNAsensor$date == temp$date[1]): which(dropNAsensor$date == tail(temp$date, n=1))] <-    
        sensor$no[which(sensor$date == temp$date[1]): which(sensor$date == tail(temp$date, n=1))]
    }

  }
  
}

sensor$correctedNO[which(sensor$date %in% dropNAsensor$date)] <- dropNAsensor$correctedNO # replace values based on date 
return(sensor$correctedNO)
}
```


```{r}
sn45_cpc <- no_ae_filter(sn45_cpc)
sn45_cpc$correctedNO <- no_baseline_filter(sn45_cpc)
```


Last time, we created an NO2 model variable, based on NO2 model code that Eben had. Since we don't have one this time, I will not include it. 


# Time Sync

4.	Time sync - The CPC is at 1 s and the Aethalometer is 1 min. QuantAQ is 1 min. Probably best to time sync to the same 1 min time basis as the QuantAQ nodes. All of them are on exactly the same time stamp, because I time synced all of the instruments when I put them in the field on the 23rd. 

```{r}
time_sync <- function(sensor){
  sensor <- mutate(sensor, originaldate = date) #keeping original times for comparing to flight data
  sensor$date <- round_date(ymd_hms(sensor$date, tz="America/New_York"), unit="minute") #round date for merging
  sensor<- sensor[order(sensor$originaldate),] #put it in chronological order
  setDT(sensor, key = "date") #change object type to data.table
  sensor <- unique(sensor, by = "date") #remove duplicates
  
  return(sensor)

}
```

```{r}
sn45_cpc <- time_sync(sn45_cpc)
sn46_cpc <- time_sync(sn46_cpc)

aeth_data <- time_sync(aeth_data)
```


```{r}
cpc_timesync <- cpc_upload[, c("concent", "fillcnt","date")]

cpc_timesync$date5min <- round_date(cpc_timesync$date, "1 min")
cpc_timesync_1min <- aggregate(cpc_timesync[, names(cpc_timesync) != "date5min"], by = list(cpc_timesync$date5min), FUN = mean, na.rm = TRUE)
```




-> have to fix fillcnt 

# Compare 


```{r}
#comparing matrix 

#comp_matrx <- cbind(sn45_cpc[, c("timestamp_local", "temp_manifold", "co2", "wind_dir", "no2", "co", "correctedNO")], sn46_cpc[, c("timestamp_local", "temp_manifold", "co2", "wind_dir", "no2", "co", "correctedNO")], aeth_data, cpc_timesync_1min)

comp_matrx <- cbind(sn45_cpc[, c("timestamp_local", "temp_manifold", "co2", "wind_dir", "no2", "co", "no")], sn46_cpc[, c("timestamp_local", "temp_manifold", "co2", "wind_dir", "no2", "co", "no")], aeth_data, cpc_timesync_1min)

```

```{r}
#timePlot(comp_matrx, pollutant = c("UV BC1", "Blue BC1", "Green BC1", "Red BC1", "IR BC1"))
```


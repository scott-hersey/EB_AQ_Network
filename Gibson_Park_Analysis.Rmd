---
title: "Initial Analysis Walkthrough"
#output: html_notebook
---

# Overview

This code combines multiple monthly data files from QuantAQ instruments (ARISense and Modulair-PM), syncs them with meteorology data. It includes downloading, cleaning, and doing a high level analysis of the data. At the end, we will export the cleaned datasets. These can be used as inputs to the following two walkthroughs: regime definitions and co-location. 

# Downloading and Importing

We're going to be using two datasets: QuantAQ pollutant concentration data from the [QuantAQ website](https://www.quant-aq.com/) and meteorology data from the [Iowa Environmental Mesonet](https://mesonet.agron.iastate.edu/request/download.phtml?network=MA_ASOS).

Note: The paragraph above and the following section will describe the downloading, storing and importing process for a normal workflow. However, there is not always the option of using this normal workflow. After the following downloading, storing and importing sections, there will be a section that describes how to do these things when you need to use the QuantAQ data from the [DropBox folder](https://app.box.com/s/3rs3dasqitqtrwxgtem0ef96jhkbnqtm). 

## QuantAQ Data 

Download all of the monthly QuantAQ files you're interested in analyzing.

## Meteorology Data 

Select the following station: 
* [BOS] BOSTON/LOGAN INTL

Select the following variables: 

* Wind Direction
* Wind Speed [mph]
* Temperature (C)

Select the date range: 
* 9/7/2019 to 3/8/2021 (this dataset is not inclusive of the last date)

Select this timezone: 
* America/New_York 


Use the following download options:
* csv 
* no latitude/ longitude vectors 
* represent missing data with blank string
* denote trace with blank string

## Storing the data 

In order to easily import the data, we'll store the data in the following way: 

* Store all the QuantAQ data in the folder called "quant_aq", which is a subfolder in "/data" folder of this workspace. Save ARISense (or Modulair) data and Modulair-PM data separately (/ARISense and /MOD-PM, respectively). 
* Store the meteorology data in the "/data" folder in this workspace. Store the file as "metdata.csv"


```{r, warning= FALSE, error = FALSE}
library(lubridate) #date and time functions 
library(data.table) #to use the data.table variable type
library(dplyr) #this library allows you to use the %>% operator
library(tidyr) #this library lets you use the complete function to account for time syncing
library(openair) #for plotting and analysis
library(stringr)
library(baseline) # for baseline correction
library(purrr)
library(tidyverse)

```


```{r}

ARISense <-
    list.files(path = "./data/quant_aq/ARISense/",
               pattern = "*.csv", 
               full.names = T) %>% 
    map_df(~read_csv(.)) 

ARISense$pm1num <- ARISense$bin0 + ARISense$bin1 + ARISense$bin2
ARISense$date <- as.POSIXct(strptime(ARISense$timestamp_local, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York"))


```


```{r}

modPM <-
    list.files(path = "./data/quant_aq/Modulair-PM/",
               pattern = "*.csv", 
               full.names = T) %>% 
    map_df(~read_csv(.)) 

modPM$pm1num <- modPM$bin0 + modPM$bin1 + modPM$bin2
modPM$date <- as.POSIXct(strptime(modPM$timestamp_local, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York"))

```



# Import Meteorology data

First, we import the file. We can indicate that there is a header. 

```{r}
metdata <- fread("data/metdata.csv", header=TRUE, data.table = TRUE) #import meteorology file
metdata$date <- as.POSIXct(metdata$valid, format = "%Y-%m-%d %H:%M", tz = "America/New_York") #setting datetime, using correct timezone on East Coast Local time

metdata <- metdata %>%
  # if only wind speed and wind direction matter
  setnames(old = c("drct", "sped", "valid"), new = c("wd", "ws", "original_met_time")) %>% #rename
  na.omit("date") %>% #if any dates are NA, the following function won't work
  complete(date = seq(from = min(date), to= max(date),  by = "1 min")) %>%#make 1 minute intervals
  fill(c("wd", "ws", "tmpc")) #fill those new 1 minute interval rows

metdata$ws <- metdata$ws * (1609/3600) #converting to m/s, 1609 meters per mile, 3600 seconds per hr
metdata[,c( "station")] <- list(NULL) #getting rid of unnecessary variables
metdata <- unique(metdata) #remove duplicates
```



```{r}
# Time sync and merge met and pollution data
ARISense$ARISense_date_1min <- round_date(ARISense$date, unit="minute") #round date for merging
modPM$modPM_date_1min <- round_date(modPM$date, unit="minute") #round date for merging
metdata$met_date_1min <- round_date(metdata$date, unit="minute") #round date for merging
```



```{r}
ARISense_met <- left_join(ARISense, metdata, by = c("ARISense_date_1min" = "met_date_1min"))
modPM_met <- left_join(modPM, metdata, by = c("modPM_date_1min" = "met_date_1min"))

ARISense_met$date <- ARISense_met$date.x
modPM_met$date <- modPM_met$date.x


```



```{r}
# Sanity check wind time series

timeVariation(ARISense_met, pollutant = c("ws", "wd", "tmpc"), normalise = TRUE)
timeVariation(modPM_met, pollutant = c("ws", "wd", "tmpc"), normalise = TRUE)
```


Data Cleaning


## Remove CO spikes from ARISense data
```{r}
removeCOspikes <- function(ARISense_met){
  #calculate how much time elapses between data points
  ARISense_met$timediff <- c(NA, difftime(ARISense_met$date[-1],
                               ARISense_met$date[-nrow(sensor)],
                               units="mins"))
  #find where there are jumps of an hour or more
  jump_indices <- which(ARISense_met$timediff > 60)
  # set up which indices should be removed from the data 
  ARISense_met$removeCO <- "FALSE"
  for(jump_index in jump_indices){
    ARISense_met[jump_index:(jump_index+20), removeCO := "TRUE"] 
  }
  #remove CO 
  ARISense_met$co[ARISense_met$removeCO == "TRUE"] <- NA 
  
  return(ARISense_met)
}
```

## Remove CO spikes from ARISense data
```{r}
removeCOspikes <- function(ARISense_met){
  #calculate how much time elapses between data points
  ARISense_met$timediff <- c(NA, difftime(ARISense_met$date[-1],
                               ARISense_met$date[-nrow(sensor)],
                               units="mins"))
  #find where there are jumps of an hour or more
  jump_indices <- which(ARISense_met$timediff > 60)
  # set up which indices should be removed from the data 
  ARISense_met$removeCO <- "FALSE"
  for(jump_index in jump_indices){
    ARISense_met[jump_index:(jump_index+20), removeCO := "TRUE"] 
  }
  #remove CO 
  ARISense_met$co[ARISense_met$removeCO == "TRUE"] <- NA 
  
  return(ARISense_met)
}
```

# remove bin0 = 0 for bins 0-4

```{r}
# thresholds for removal
rh_manifold_threshold <- 100
wd_threshold <- 360
ws_threshold <- 100
bin0_threshold <- 2000
bin1_threshold <- 2000
bin2_threshold <- 2000
bin3_threshold <- 2000
bin4_threshold <- 2000
bin5_threshold <- 2000
bin6_threshold <- 2000
pm1_threshold <- 800
pm25_threshold <- 1000
pm10_threshold <- 1000
no2_threshold <- 300
no_threshold <- 300
o3_threshold <- 500
co_threshold <- 500
co2_threshold <- 1000

```

```{r}


# removing values above thresholds
ARISense_met$rh_manifold <- replace(ARISense_met$rh_manifold,ARISense_met$rh_manifold >rh_manifold_threshold, NA)
ARISense_met$wd <- replace(ARISense_met$wd,ARISense_met$wd >wd_threshold, NA)
ARISense_met$ws <- replace(ARISense_met$ws,ARISense_met$ws >ws_threshold, NA)
ARISense_met$bin0 <- replace(ARISense_met$bin0,ARISense_met$bin0 >bin0_threshold, NA)
ARISense_met$bin1 <- replace(ARISense_met$bin1,ARISense_met$bin1 >bin1_threshold, NA)
ARISense_met$bin2 <- replace(ARISense_met$bin2,ARISense_met$bin2 >bin2_threshold, NA)
ARISense_met$bin3 <- replace(ARISense_met$bin3,ARISense_met$bin3 >bin3_threshold, NA)
ARISense_met$bin4 <- replace(ARISense_met$bin4,ARISense_met$bin4 >bin4_threshold, NA)
ARISense_met$bin5 <- replace(ARISense_met$bin5,ARISense_met$bin5 >bin5_threshold, NA)
ARISense_met$bin6 <- replace(ARISense_met$bin6,ARISense_met$bin6 >bin6_threshold, NA)
ARISense_met$pm1 <- replace(ARISense_met$pm1,ARISense_met$pm1 >pm1_threshold, NA)
ARISense_met$pm25 <- replace(ARISense_met$pm25,ARISense_met$pm25 >pm25_threshold, NA)
ARISense_met$pm10 <- replace(ARISense_met$pm10,ARISense_met$pm10 >pm10_threshold, NA)
ARISense_met$no2 <- replace(ARISense_met$no2,ARISense_met$no2 >no2_threshold, NA)
ARISense_met$no <- replace(ARISense_met$no,ARISense_met$no >no_threshold, NA)
ARISense_met$o3 <- replace(ARISense_met$o3,ARISense_met$o3 >o3_threshold, NA)
ARISense_met$co <- replace(ARISense_met$co,ARISense_met$co >co_threshold, NA)
ARISense_met$co2 <- replace(ARISense_met$co2,ARISense_met$co2 >co2_threshold, NA)

modPM_met$opcn3_rh <- replace(modPM_met$opcn3_rh,modPM_met$opcn3_rh >rh_manifold_threshold, NA)
modPM_met$wd <- replace(modPM_met$wd,modPM_met$wd >wd_threshold, NA)
modPM_met$ws <- replace(modPM_met$ws,modPM_met$ws >ws_threshold, NA)
modPM_met$bin0 <- replace(modPM_met$bin0,modPM_met$bin0 >bin0_threshold, NA)
modPM_met$bin1 <- replace(modPM_met$bin1,modPM_met$bin1 >bin1_threshold, NA)
modPM_met$bin2 <- replace(modPM_met$bin2,modPM_met$bin2 >bin2_threshold, NA)
modPM_met$bin3 <- replace(modPM_met$bin3,modPM_met$bin3 >bin3_threshold, NA)
modPM_met$bin4 <- replace(modPM_met$bin4,modPM_met$bin4 >bin4_threshold, NA)
modPM_met$bin5 <- replace(modPM_met$bin5,modPM_met$bin5 >bin5_threshold, NA)
modPM_met$bin6 <- replace(modPM_met$bin6,modPM_met$bin6 >bin6_threshold, NA)
modPM_met$pm1 <- replace(modPM_met$pm1,modPM_met$pm1 >pm1_threshold, NA)
modPM_met$pm25 <- replace(modPM_met$pm25,modPM_met$pm25 >pm25_threshold, NA)
modPM_met$pm10 <- replace(modPM_met$pm10,modPM_met$pm10 >pm10_threshold, NA)


```

```{r}


# removing zeroes and negatives
ARISense_met$o3 <- replace(ARISense_met$o3, ARISense_met$o3 < 0, 0)
ARISense_met$co <- replace(ARISense_met$co, ARISense_met$co <0, NA)
ARISense_met$co2 <- replace(ARISense_met$co2, ARISense_met$co2 <0, NA)
ARISense_met$no2 <- replace(ARISense_met$no2, ARISense_met$no2 <0, NA)
ARISense_met$bin0 <- replace(ARISense_met$bin0, ARISense_met$bin0 <0, NA)
ARISense_met$pm1 <- replace(ARISense_met$pm1, ARISense_met$pm1 <0, NA)
ARISense_met$pm10 <- replace(ARISense_met$pm10, ARISense_met$pm10 <0, NA)
ARISense_met$pm25 <- replace(ARISense_met$pm25, ARISense_met$pm25 <0, NA)


modPM_met$bin0 <- replace(modPM_met$bin0, modPM_met$bin0 <0, NA)
modPM_met$pm1 <- replace(modPM_met$pm1, modPM_met$pm1 <0, NA)
modPM_met$pm10 <- replace(modPM_met$pm10, modPM_met$pm10 <0, NA)
modPM_met$pm25 <- replace(modPM_met$pm25, modPM_met$pm25 <0, NA)
```


## Perform an NO baseline correction - working?
```{r}
  # create day column
  ARISense_met$day <- as.Date(ARISense_met$date, format="%Y-%m-%d", tz = "America/New_York")
  
  # create corrected column
  ARISense_met$correctedNO <- seq(0,0,length.out= length(ARISense_met$no))
  ARISense_met$correctedNO[ARISense_met$correctedNO == 0] <- NA  #set them actually to NA
  
  dropNAsensor<- ARISense_met[!is.na(ARISense_met$no), ] # drop NO NAs
  unique_days <- c(unique(dropNAsensor$day, na.rm=TRUE)) #get all of the unique days in the sensor

  
  for (i in 2:(length(unique_days)-1)){ #for all days
    temp <- subset(dropNAsensor, day %in% unique_days[i], c("day", "no", "date")) #create temp dataset
  
    if (nrow(temp) > 550){
      wholebase.peakDetection <- baseline(t(temp$no), method='peakDetection',left=50, right=50, lwin=10, rwin=10) #baseline correction
  
    #replace the correctedNO column values with the baseline correction from earlier
    dropNAsensor$correctedNO[which(dropNAsensor$date == temp$date[1]): which(dropNAsensor$date == tail(temp$date, n=1))] <-    c(getCorrected(wholebase.peakDetection))
    }
  
    else{
      if (sum(temp$no < 0, na.rm = TRUE) / nrow(temp) < 0.25){
        dropNAsensor$correctedNO[which(dropNAsensor$date == temp$date[1]): which(dropNAsensor$date == tail(temp$date, n=1))] <-
          ARISense_met$no[which(ARISense_met$date == temp$date[1]): which(ARISense_met$date == tail(temp$date, n=1))]
      }
  
    }
  
  }
  
  ARISense_met$correctedNO[which(ARISense_met$date %in% dropNAsensor$date)] <- dropNAsensor$correctedNO # replace values based on date
  

```


```{r}
# Truncate dataset for times that are good


```


```{r}
# initial time plots for sanity

class(date)
timePlot(ARISense_met, pollutant = c("wd", "ws"))
# 
timePlot(ARISense_met, pollutant = c("correctedNO", "no2"))
# timePlot(ARISense_met, pollutant = c("pm1", "pm25", "pm10"))
# timePlot(ARISense_met, pollutant = c("bin0", "bin1", "bin2"))
# timePlot(ARISense_met, pollutant = "co")

timePlot(modPM_met, pollutant = c("pm1", "pm25", "pm10"))
timePlot(modPM_met, pollutant = c("wd", "ws"))

```
```{r}
# Truncate for PM - when was ARISense PM good?
ARISense_met_pm <- subset(ARISense_met, ARISense_met$date < "2021-04-01 00:00:00")

```



```{r}
# Diurnals

timeVariation(ARISense_met, pollutant = c("correctedNO", "no2", "co"), local.tz= "America/New_York", normalise = TRUE) 
timeVariation(ARISense_met, pollutant = c("correctedNO", "no2"), local.tz= "America/New_York") 
timeVariation(ARISense_met, pollutant = c("co"), local.tz= "America/New_York") 
timeVariation(modPM_met, pollutant = c("pm1", "pm25", "pm10"), local.tz= "America/New_York") 

```
```{r}
# Polar Plots - IQR
ARISense_met_nz <- ARISense_met
ARISense_met_nz$ws[ARISense_met_nz$ws==0]<-NA

modPM_met_nz <- modPM_met
modPM_met_nz$ws[modPM_met_nz$ws==0]<-NA

```

```{r}
# Polar Plots - IQR
 polarPlot(ARISense_met_nz, pollutant = "correctedNO", uncertainty = TRUE, main = paste0("Gibson Park ", "NO Polar Plot", sep= " "))
 polarPlot(ARISense_met_nz, pollutant = "no2",uncertainty = TRUE,  main = paste0("Gibson Park ", "NO2 Polar Plot", sep= " "))
  polarPlot(ARISense_met_nz, pollutant = "co", uncertainty = TRUE, main = paste0("Gibson Park ", "CO Polar Plot", sep= " "))
  polarPlot(modPM_met_nz, pollutant = "pm1", uncertainty = TRUE, limits = c(0,15), main = paste0("Gibson Park ", "PM1 Polar Plot", sep= " "))
  polarPlot(modPM_met_nz, pollutant = "pm25",uncertainty = TRUE,  limits = c(0,20), main = paste0("Gibson Park ", "PM2.5 Polar Plot", sep= " "))
  polarPlot(modPM_met_nz, pollutant = "pm10",uncertainty = TRUE, limits = c(0,30),  main = paste0("Gibson Park ", "PM10 Polar Plot", sep= " "))
```




```{r}
# Polar Plots as weighted mean
 polarPlot(ARISense_met_nz, pollutant = "correctedNO", statistic = "weighted.mean",normalise = TRUE, main = paste0("Gibson Park ", "NO Polar Plot", sep= " "))
 polarPlot(ARISense_met_nz, pollutant = "no2",statistic = "weighted.mean",  normalise = TRUE,main = paste0("Gibson Park ", "NO2 Polar Plot", sep= " "))
  polarPlot(ARISense_met_nz, pollutant = "co", statistic = "weighted.mean", normalise = TRUE,main = paste0("Gibson Park ", "CO Polar Plot", sep= " "))
  polarPlot(modPM_met_nz, pollutant = "pm1", statistic = "weighted.mean", normalise = TRUE,main = paste0("Gibson Park ", "PM1 Polar Plot", sep= " "))
  polarPlot(modPM_met_nz, pollutant = "pm25",statistic = "weighted.mean", normalise = TRUE, main = paste0("Gibson Park ", "PM2.5 Polar Plot", sep= " "))
  polarPlot(modPM_met_nz, pollutant = "pm10",statistic = "weighted.mean", normalise = TRUE, main = paste0("Gibson Park ", "PM10 Polar Plot", sep= " "))
```



```{r}

 polarFreq(ARISense_met_nz, pollutant = "correctedNO",  statistic = "weighted.mean", main = paste0("Gibson Park ", "NO Polar Plot", sep= " "))
 polarFreq(ARISense_met_nz, pollutant = "no2", statistic = "weighted.mean", main = paste0("Gibson Park ", "NO2 Polar Plot", sep= " "))
  polarFreq(ARISense_met_nz, pollutant = "co", statistic = "weighted.mean", main = paste0("Gibson Park ", "CO Polar Plot", sep= " "))
  polarFreq(modPM_met_nz, pollutant = "pm1",  statistic = "weighted.mean", main = paste0("Gibson Park ", "PM1 Polar Plot", sep= " "))
  polarFreq(modPM_met_nz, pollutant = "pm25", statistic = "weighted.mean",  main = paste0("Gibson Park ", "PM2.5 Polar Plot", sep= " "))
  polarFreq(modPM_met_nz, pollutant = "pm10", statistic = "weighted.mean",  main = paste0("Gibson Park ", "PM10 Polar Plot", sep= " "))
```

```{r}
polarFreq(ARISense_met_nz, pollutant = "correctedNO", ws.int = 30, statistic = "weighted.mean", offset = 80, trans = FALSE, col = "heat", main = paste0("Gibson Park ", "NO Polar Plot", sep= " "))
polarFreq(modPM_met_nz, pollutant = "pm1", ws.int = 30, statistic = "weighted.mean", offset = 80, trans = FALSE, col = "heat", main = paste0("Gibson Park ", "PM1 Polar Plot", sep= " "))
polarFreq(modPM_met_nz, pollutant = "pm25", ws.int = 30, statistic = "weighted.mean", offset = 80, trans = FALSE, col = "heat", main = paste0("Gibson Park ", "PM2.5 Polar Plot", sep= " "))
polarFreq(modPM_met_nz, pollutant = "pm10", ws.int = 30, statistic = "weighted.mean", offset = 80, trans = FALSE, col = "heat", main = paste0("Gibson Park ", "PM10 Polar Plot", sep= " "))
```
```{r}
polarFreq(ARISense_met_nz, pollutant = "correctedNO", ws.int = 30, statistic = "frequency", offset = 80, trans = FALSE, col = "heat")
polarFreq(modPM_met_nz, pollutant = "pm1", ws.int = 30, statistic = "frequency", offset = 80, trans = FALSE, col = "heat")
polarFreq(modPM_met_nz, pollutant = "pm25", ws.int = 30, statistic = "frequency", offset = 80, trans = FALSE, col = "heat")
polarFreq(modPM_met_nz, pollutant = "pm10", ws.int = 30, statistic = "frequency", offset = 80, trans = FALSE, col = "heat")
```
```{r}
polarFreq(ARISense_met_nz, pollutant = "correctedNO", ws.int = 30,  offset = 80, trans = FALSE, col = "heat")
polarFreq(modPM_met_nz, pollutant = "pm1", ws.int = 30,  offset = 80, trans = FALSE, col = "heat")
polarFreq(modPM_met_nz, pollutant = "pm25", ws.int = 30,  offset = 80, trans = FALSE, col = "heat")
polarFreq(modPM_met_nz, pollutant = "pm10", ws.int = 30,  offset = 80, trans = FALSE, col = "heat")
```

```{r}
# Polar Maps
library(openairmaps)
```



```{r}
# Make Polar Clusters
polarCluster(modPM_met, pollutant = "pm1", n.clusters = 2:10, cols= "Set2", main = paste0("Gibson Park"))

polarCluster(modPM_met, pollutant = "pm25", n.clusters = 2:10, cols= "Set2", main = paste0("Gibson Park"))

polarCluster(modPM_met, pollutant = "pm10", n.clusters = 2:10, cols= "Set2", main = paste0("Gibson Park"))
```


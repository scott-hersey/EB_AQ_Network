---
title: "R Notebook"
---

# Description 

In this notebook, I clean the sensor data from Little Folks.

## Acknowledgements

This code is based heavily off of work done by Alli Busa.

# Environment Setup 

Import the necessary libraries. 

```{r, warning= FALSE, error = FALSE}
library(lubridate) #date and time functions 
library(data.table) #to use the data.table variable type
library(dplyr) #this library allows you to use the %>% operator
library(tidyr) #this library lets you use the complete function to account for time syncing
library(openair) #for plotting and analysis
library(stringr)
```

---------------------------------------------------------------------------------------------------------------------------------------------

# Prepare CPC data 

## Import CPC data 

We're going to take the CPC from every day of the experiment (each day's data is given as a TXT file), and combine in into one data frame that represents all the CPC data from a given room. 

```{r}
outdoorLF_cpc_files <- list.files(path="./Little Folks/Outdoor", pattern="*.TXT", full.names = TRUE)
outdoorLF_cpc <- do.call(rbind, lapply(outdoorLF_cpc_files, function(x) fread(file=x, header = TRUE, data.table = TRUE, skip="#YY/MM/DD", fill=TRUE) ) ) 

class2_cpc_files <- list.files(path="./Little Folks/Class 2 - paired outdoor", pattern="*.TXT", full.names = TRUE)
class2_cpc <-  do.call(rbind, lapply(class2_cpc_files, function(x) fread(file=x, header = TRUE, data.table = TRUE, skip="#YY/MM/DD", fill=TRUE) ) ) 

class4_cpc_files <- list.files(path="./Little Folks/Class 4", pattern="*.TXT", full.names = TRUE)
class4_cpc <-  do.call(rbind, lapply(class4_cpc_files, function(x) fread(file=x, header = TRUE, data.table = TRUE, skip="#YY/MM/DD", fill=TRUE) ) ) 
```
Now, we will combine the CPC data from all three locations into one list of dataframes, similar to how we created a list of dataframes in the initial walkthrough of Eastie, on line 119. We will do this so we can apply functions to the data with greater ease. 

```{r}
LF_cpc_list <- list( "outdoor" = outdoorLF_cpc, 
                     "class2" = class2_cpc, 
                     "class4" = class4_cpc)
```

```{r}
LF_cpc_list
```

## Setting the correct datetime

We combine the date and time columns in the cpc data to create datetime objects. 
```{r}
LF_cpc_list$outdoor$date <- with(LF_cpc_list$outdoor, ymd(`#YY/MM/DD`) + hms(`HR:MN:SC`)) ##formatting datetime
tz(LF_cpc_list$outdoor$date) <- "America/New_York" # define timezone

LF_cpc_list$class2$date <- with(LF_cpc_list$class2, ymd(`#YY/MM/DD`) + hms(`HR:MN:SC`)) ##formatting datetime
tz(LF_cpc_list$class2$date) <- "America/New_York" # define timezone

LF_cpc_list$class4$date <- with(LF_cpc_list$class4, ymd(`#YY/MM/DD`) + hms(`HR:MN:SC`)) ##formatting datetime
tz(LF_cpc_list$class4$date) <- "America/New_York" # define timezone
```

## Cleaning the data for non-numerical errors 

I had found that the data isn't always imported in the right format (ie as strings instead of numeric), which leads to problems when you want to perform operations on those data. In order to solve this, we are checking the column type of each dataset, determining where there are outliers, and fixing the formatting issues. 

We'll check the data format of each column in each data set. Numeric data should be "double" or "integer".

```{r}
sapply(LF_cpc_list, function(x) sapply(x,typeof))
```

## Cleaning the data for numerical errors 

Now, we'll clean the data according the guidelines we set in place in our 'Expected Values' spreadsheet. 

### Discard all zero and negative values 

```{r}
lapply(LF_cpc_list, function(x) sprintf("Number of negative and zero values: %d", sum(x$concent <= 0, na.rm = TRUE)))
```
Now, we can clean the rest. 

```{r}
LF_cpc_list <- sapply(LF_cpc_list, function(x) {
  x$concent[x$concent <= 0] <- NA
  return(x)}
       )
```

Let's also check how many values are NA: 

```{r}
lapply(LF_cpc_list, function(x) sprintf("Number of NA values: %d", sum(is.na(x$concent))))
lapply(LF_cpc_list, function(x) sprintf("Percentage of NA values: %f", 100*(sum(is.na(x$concent)) / nrow(x))))
```
### Check low and high values 

First, we'll check how many values are below 1000: 

```{r}
lapply(LF_cpc_list, function(x) sprintf("Number of values below 1000 particles/cm3: %d", sum(x$concent < 1000, na.rm = TRUE)))
lapply(LF_cpc_list, function(x) sprintf("Percentage of values below 1000 particles/cm3: %f", 100*(sum(x$concent < 1000, na.rm = TRUE)/ nrow(x))))
```
Next, we'll check how many values are above 100000: 

```{r}
lapply(LF_cpc_list, function(x) sprintf("Number of values above 100000 particles/cm3: %d", sum(x$concent > 100000, na.rm = TRUE)))
lapply(LF_cpc_list, function(x) sprintf("Percentage of values above 100000 particles/cm3: %f", 100*sum(x$concent > 100000, na.rm = TRUE)/ nrow(x)))
```

---------------------------------------------------------------------------------------------------------------------------------------------

# Preparing the PM data 

## Importing the PM data 

Now we will import all the PM data, using the same method as for the CPC data. We will combine the three PM data frames into one list of dataframes. Lastly, we will clean all the dataframes in the list of dataframes using the function above. 

```{r}
# import pm data 

LF_outdoor_PM <- do.call(cbind, lapply(list.files(path="./Modulair-PM Data", pattern="114.*.csv", full.names = TRUE), function(x) fread(file=x, header = TRUE)))

LF_class1_PM <- do.call(cbind, lapply(list.files(path="./Modulair-PM Data", pattern="104.*.csv", full.names = TRUE), function(x) fread(file=x, header = TRUE)))

LF_class2_PM <- do.call(cbind, lapply(list.files(path="./Modulair-PM Data", pattern="126.*.csv", full.names = TRUE), function(x) fread(file=x, header = TRUE)))

LF_class3_PM <- do.call(cbind, lapply(list.files(path="./Modulair-PM Data", pattern="125.*.csv", full.names = TRUE), function(x) fread(file=x, header = TRUE)))

LF_class4_PM <- do.call(cbind, lapply(list.files(path="./Modulair-PM Data", pattern="099.*.csv", full.names = TRUE), function(x) fread(file=x, header = TRUE)))

LF_admin_PM <- do.call(cbind, lapply(list.files(path="./Modulair-PM Data", pattern="111.*.csv", full.names = TRUE), function(x) fread(file=x, header = TRUE)))

# combine PM data 

LF_pm_list = list("outdoor" = LF_outdoor_PM,
                  "class1" = LF_class1_PM,
                  "class2" = LF_class2_PM,
                  "class3" = LF_class3_PM,
                  "class4" = LF_class4_PM,
                  "admin" = LF_admin_PM)
```

## Setting the correct datetime

The first step for this subsection is to clean the PM data. This involves setting it to a datetime object, changing the timezone from UTC to EST/EDT, and rounding the datetime object so that the data can be matched with the CPC data, minute by minute. 

```{r}
clean_PM_data <- function(sensor){
  indx = which(!duplicated(colnames(sensor))) #find duplicate columns
  sensor <- subset(sensor, select = indx) #remove duplicate columns from the pm files
  sensor$date <- ymd_hms(sensor$timestamp, tz="UTC") #parse datetime
  sensor$date <- with_tz(sensor$date, "America/New_York") #change the time according to shifted timezone
  sensor$original_date <- sensor$date
  sensor$date <- round_date(ymd_hms(sensor$date, tz="America/New_York"), unit="minute") #round date for merging
  sensor<- sensor[order(sensor$original_date),] #put it in chronological order
  return(sensor)
}
```

Now, we'll apply it. 

```{r}
LF_pm_list <- lapply(LF_pm_list,  function(x) clean_PM_data(x)) # convert pm data to local time, round date 
```

## Cleaning the data for non-numerical errors

As before, we'll check for non-numerical errors. 

```{r}
sapply(LF_pm_list, function(x) sapply(x,typeof))
```

Everything here looks okay, for our purposes.

## Cleaning the data for numerical errors 

According to our spreadsheet, pm1 shouldn't exceed 1 microgram/m3, and should never be negative. 

```{r}
lapply(LF_pm_list, function(x) sprintf("Number of negative values: %d", sum(x$pm1 < 0, na.rm = TRUE)))
```
There are no negative values. 

---------------------------------------------------------------------------------------------------------------------------------------------

# Merging 

## Averaging CPC data 

In order to merge with the PM data, we have to get the data to have the same time intervals. This way, we will be able to match datapoints based on what time they were taken. Since the PM data has a smaller resolution than the CPC data (1 min opposed to 1 sec), we will average the CPC data so that it will be on a 1 minute time basis. 

To do this, we will create a date1min vector in the CPC data; this vector gives the datetime rounded to the nearest minute for each datapoint. Then we will take all of the numeric data, group them into categories so that each category has the same date1min, and then taking the mean of each group. 

```{r}
average_cpc <- function(cpc){
  
  cpc$date1min <- round_date(cpc$date, "1 min") #creating date1min vector. Turns 00:00:01 and 00:00:59 into 00:00 and 00:01, respectively.
  
  new_cpc <- cpc %>% 
    select(c("date1min", "aveconc","concent","rawconc", "cnt_sec",    "condtmp",   "satttmp",   "satbtmp",   "optctmp",   "inlttmp" ,  "smpflow" ,  "satflow", "pressur",   "condpwr",   "sattpwr" ,  "satbpwr" ,  "optcpwr",   "satfpwr" ,  "fillcnt",  "err_num")) %>% 
    dplyr::group_by(date1min) %>%  
    mutate_if(is.character,as.numeric) %>%  #converting strings to numeric
    dplyr::summarize(across(everything(), list(mean), na.rm= TRUE))
    
  return(new_cpc)
}
```

Let's check that all the columns are in the right format, again. 

```{r}
sapply(LF_cpc_list, function(x) sapply(x,typeof))
```
And making sure there aren't any rows that could stop us from taking the mean: 

```{r}
sapply(LF_cpc_list, function(x) which(is.na(x$date)))
```
Since there aren't any issues, we can apply the function.
```{r}
LF_cpc_list2 <- lapply(LF_cpc_list, average_cpc)
```


## Merging Function 

The function we are using is also based on line 74 of the initial analysis walkthrough. 

```{r}
LF_rooms <- sapply(names(LF_cpc_list), function(k) merge(LF_cpc_list2[[k]], LF_pm_list[[k]], by.x = "date1min", by.y = "date", all = TRUE), simplify = FALSE,USE.NAMES = TRUE)
```

---------------------------------------------------------------------------------------------------------------------------------------------

# Apply Correction Factor 

As stated in the HEPA Analysis powerpoint, here we will "multiply CPC concentrations by a static value to account for noise from the sensors." We do this by creating a function, which takes in a dataframe and a correction factor. It multiplies that dataframe's concent vector by the input correction factor.  

```{r}
apply_correction <- function(sensor, correctionfactor){
  sensor$concent <- (sensor$concent) * correctionfactor
  return(sensor)
}
```

The correction data is based on which sensor is used. Below, we list which sensor is used in each location.

015 - class2
016 - outdoor
077 - class4

We apply that function to all of the dataframes:
```{r}
LF_rooms_previous = LF_rooms # replicating the list, to check the function

LF_rooms["class2"] <- apply_correction(LF_rooms["class2"], 0.9449454)

LF_rooms["outdoor"] <- apply_correction(LF_rooms["outdoor"], 1.005473)

LF_rooms["class4"] <- apply_correction(LF_rooms["class4"],  1.100486)
```

We can check that the concentration vector still stays the same: 

```{r}
all(LF_rooms_previous$class2$concent == LF_rooms$class2$concent, na.rm = TRUE)
all(LF_rooms_previous$outdoor$concent == LF_rooms$outdoor$concent, na.rm = TRUE)
all(LF_rooms_previous$class4$concent == LF_rooms$class4$concent)
```


---------------------------------------------------------------------------------------------------------------------------------------------

# Generating indoor/outdoor ratios 

We will create a function that merges two dataframes (a dataframe from a testing location inside, and from outside).

```{r}
ratio_merge <- function(room_df, outdoor_df, cpc = TRUE){
  
  # if the dataset has CPC data
  if(cpc == TRUE){
    ratio_df <- merge(room_df, outdoor_df, by.x = "date1min", by.y = "date1min", all.x = TRUE, suffixes = c(".indoor", ".outdoor")) #merge the data from the room and the outdoors
  
    ratio_df$pm1_ratio <- ratio_df$pm1.indoor / ratio_df$pm1.outdoor #create a column that's a ratio of pm1's
    
    ratio_df$concent_ratio <- ratio_df$concent_1.indoor / ratio_df$concent_1.outdoor #create a column that's a ratio of cpc
  }
  
  #if the data doesn't have CPC data
  else{
    ratio_df <- merge(room_df, outdoor_df, by.x = "date", by.y = "date1min", all.x = TRUE, suffixes = c(".indoor", ".outdoor"))
  
    ratio_df$pm1_ratio <- ratio_df$pm1.indoor / ratio_df$pm1.outdoor
    
  }
  
  return(ratio_df)
  
}
```


We'll run this function on the datasets. 

```{r}
LF_class1_ratio <- ratio_merge(LF_pm_list$class1, LF_rooms$outdoor, cpc = FALSE)
LF_class2_ratio <- ratio_merge(LF_rooms$class2, LF_rooms$outdoor, cpc = TRUE)
LF_class3_ratio <- ratio_merge(LF_pm_list$class3, LF_rooms$outdoor, cpc = FALSE)
LF_class4_ratio <- ratio_merge(LF_rooms$class4, LF_rooms$outdoor, cpc = TRUE)

LF_admin_ratio <- ratio_merge(LF_pm_list$admin, LF_rooms$outdoor, cpc = FALSE)
```


---------------------------------------------------------------------------------------------------------------------------------------------

# Exporting csvs

Make a list of the new dataframes: 

```{r}
ratios <- list("LF_class1_ratio" = LF_class1_ratio,
               "LF_class2_ratio" = LF_class2_ratio,
               "LF_class3_ratio" = LF_class3_ratio,
               "LF_class4_ratio" = LF_class4_ratio,
               "LF_admin_ratio" = LF_admin_ratio)
```

Export them:

```{r}
mapply(
  write.table, #apply function write table
  x=ratios, file=paste(names(ratios), "csv", sep="."), #for each dataframe, use its name to make a csv of it
  MoreArgs=list(row.names=FALSE, sep=",")
)
```

---------------------------------------------------------------------------------------------------------------------------------------------




